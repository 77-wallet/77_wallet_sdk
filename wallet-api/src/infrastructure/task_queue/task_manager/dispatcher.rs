use crate::infrastructure::task_queue::task_manager::scheduler::TASK_CATEGORY_LIMIT;
use crate::infrastructure::task_queue::task_manager::TaskManager;
use crate::infrastructure::task_queue::{Task, TaskType};

use super::RunningTasks;

use governor::clock::DefaultClock;
use governor::state::{InMemoryState, NotKeyed};
use governor::{Quota, RateLimiter};
use once_cell::sync::Lazy;
use std::collections::HashMap;
use std::num::NonZeroU32;
use std::sync::Arc;
use tokio::sync::{mpsc, Mutex, Semaphore};
use wallet_database::entities::task_queue::TaskQueueEntity;

type Priority = u8;
pub type TaskSender = tokio::sync::mpsc::UnboundedSender<(u8, Vec<TaskQueueEntity>)>;

// static RATE_LIMITERS: Lazy<
//     std::collections::HashMap<TaskType, Arc<RateLimiter<NotKeyed, InMemoryState, DefaultClock>>>,
// > = Lazy::new(|| {
//     use TaskType::*;
//     let mut m = std::collections::HashMap::new();
//     m.insert(
//         BackendApi,
//         Arc::new(RateLimiter::direct(Quota::per_second(
//             NonZeroU32::new(50).unwrap(),
//         ))),
//     );
//     m.insert(
//         Mqtt,
//         Arc::new(RateLimiter::direct(Quota::per_second(
//             NonZeroU32::new(200).unwrap(),
//         ))),
//     );
//     m.insert(
//         Initialization,
//         Arc::new(RateLimiter::direct(Quota::per_second(
//             NonZeroU32::new(10).unwrap(),
//         ))),
//     );
//     m.insert(
//         Common,
//         Arc::new(RateLimiter::direct(Quota::per_second(
//             NonZeroU32::new(10).unwrap(),
//         ))),
//     );
//     m
// });

// fn get_rate_limiter(
//     category: &TaskType,
// ) -> Arc<RateLimiter<NotKeyed, InMemoryState, DefaultClock>> {
//     RATE_LIMITERS.get(category).cloned().unwrap()
// }

/// å¤šä¼˜å…ˆçº§ä»»åŠ¡è°ƒåº¦å™¨ `Dispatcher`
///
/// è¯¥è°ƒåº¦å™¨ç”¨äºç®¡ç†å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œï¼Œæ”¯æŒä»»åŠ¡ä¼˜å…ˆçº§è°ƒåº¦ã€ç±»å‹é™é€Ÿã€å¹¶å‘æ§åˆ¶ï¼Œå¹¶é€šè¿‡æ— é”æ¶æ„æå‡ååèƒ½åŠ›ã€‚
///
/// ### ğŸš€ è®¾è®¡æ€æƒ³
/// ç±»ä¼¼äºâ€œåˆ†å±‚ Reactor + ä»»åŠ¡åˆ†çº§æ‰§è¡Œå™¨â€ï¼Œæ¯ä¸ªä¼˜å…ˆçº§å³ä¸€ä¸ªç‹¬ç«‹çš„æ‰§è¡Œå•å…ƒï¼Œ
/// ä»»åŠ¡é—´é€šè¿‡ channel è§£è€¦ï¼Œå…·å¤‡å¤©ç„¶çš„å¹¶è¡Œæ€§ä¸éš”ç¦»æ€§ã€‚
///
///
/// ## âœ¨ æ ¸å¿ƒç‰¹æ€§
///
/// - **æ¯ä¸ªä¼˜å…ˆçº§ç‹¬ç«‹é€šé“**ï¼šæŒ‰ä¼˜å…ˆçº§è‡ªåŠ¨åˆ›å»º `UnboundedSender`ï¼Œæ¯ä¸ªä¼˜å…ˆçº§éƒ½æœ‰è‡ªå·±çš„æ¶ˆè´¹ä»»åŠ¡ï¼Œæ— éœ€å…±äº«ä»»åŠ¡é˜Ÿåˆ—æˆ–é”ã€‚
/// - **ä»»åŠ¡ç±»å‹é™é€Ÿ**ï¼šæ”¯æŒå¯¹ä¸åŒ `TaskType` çš„ä»»åŠ¡è®¾ç½®å¹¶å‘ä¸Šé™ï¼ˆå¦‚ `sync` æ¯è½®æœ€å¤šå¤„ç† N ä¸ªï¼‰ã€‚
/// - **è¿è¡Œä¸­å»é‡**ï¼šä½¿ç”¨ `RunningTasks` å»é‡ï¼Œé¿å…åŒä¸€ä¸ªä»»åŠ¡é‡å¤å¹¶å‘æ‰§è¡Œã€‚
/// - **å…¨å±€å¹¶å‘æ§åˆ¶**ï¼šä½¿ç”¨ `Semaphore` é™åˆ¶ç³»ç»Ÿæ€»å¹¶å‘ä»»åŠ¡æ•°ï¼Œé˜²æ­¢è¿‡è½½ã€‚
/// - **ä½èµ„æºå ç”¨**ï¼šæ— ä¸­å¿ƒé”ã€æ— å…¨å±€è½®è¯¢ï¼ŒæŒ‰éœ€åŠ¨æ€åˆ›å»ºæ‰§è¡Œå™¨ï¼Œç©ºé—²æ—¶ä¸ä¼šå ç”¨ CPUã€‚
///
/// ## âš™ æ¶æ„è¯´æ˜
///
/// ```text
///             ä¸Šå±‚è°ƒç”¨
///                 â”‚
///     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
///     â”‚ external_tx.send(...)   â”‚
///     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
///                  â–¼
///        Dispatcher::start_internal_task
///                  â”‚
///     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
///     â”‚ external_rx æ¥æ”¶ä»»åŠ¡     â”‚
///     â”‚ æŒ‰ priority åˆ†é…åˆ°å¯¹åº”é€šé“ â”‚
///     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
///                  â–¼
///      HashMap<Priority, UnboundedSender<TaskQueueEntity>>
///          ï¼ˆå¦‚æ— åˆ™åŠ¨æ€åˆ›å»ºï¼‰
///
///    æ¯ä¸ªä¼˜å…ˆçº§é€šé“ç»‘å®šä¸€ä¸ª Tokio ä»»åŠ¡:
///
///         UnboundedReceiver<TaskQueueEntity>
///                     â”‚
///          æ¯è½®ä»é€šé“ä¸­å–ä»»åŠ¡æ‰§è¡Œï¼š
///           - ç±»å‹é™é€Ÿï¼ˆTASK_CATEGORY_LIMITï¼‰
///           - å¹¶å‘æ§åˆ¶ï¼ˆSemaphoreï¼‰
///           - è¿è¡Œä¸­ä»»åŠ¡å»é‡
///           - æ¯ä»»åŠ¡å»¶æ—¶ï¼Œé¿å…çªå‘å†²å‡»
/// ```
///
/// ## ğŸ“Œ ç¤ºä¾‹æµç¨‹ï¼ˆæ–°ä»»åŠ¡è¿›æ¥æ—¶ï¼‰
///
/// ```text
/// 1. Dispatcher.external_tx.send((priority, Vec<TaskQueueEntity>))
/// 2. Dispatcher å†…éƒ¨ task æ¥æ”¶å¹¶éå† Vec<TaskQueueEntity>
/// 3. è‹¥è¯¥ä¼˜å…ˆçº§é€šé“ä¸å­˜åœ¨ï¼Œåˆ™åŠ¨æ€åˆ›å»º UnboundedSender + Receiver + Tokio ä»»åŠ¡
/// 4. æ¯ä¸ªä»»åŠ¡æ¨å…¥é€šé“ï¼Œç”±å…¶ç‹¬ç«‹ Tokio task å¤„ç†
/// 5. ä»»åŠ¡æ¶ˆè´¹æ—¶ï¼š
///    - é™é€Ÿæ£€æŸ¥ï¼ˆåŒç±»å‹ä»»åŠ¡æ˜¯å¦å·²è¾¾ä¸Šé™ï¼‰
///    - Semaphore æ§åˆ¶å¹¶å‘è®¸å¯
///    - ä½¿ç”¨ RunningTasks å»é‡
///    - TaskManager::process_single_task æ‰§è¡Œ
/// ```
///
///
/// ## ğŸ›  å¯é…ç½®é¡¹
///
/// - `TASK_CATEGORY_LIMIT`ï¼šé™åˆ¶æ¯ç±»ä»»åŠ¡å¹¶å‘æ•°ï¼ˆé™æ€é…ç½®ï¼‰
/// - `Semaphore(50)`ï¼šå…¨å±€æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆå¯åŠ¨æ€è°ƒæ•´ï¼‰
///
///
/// ## ğŸš§ æ³¨æ„äº‹é¡¹
///
/// - å½“å‰æ–¹æ¡ˆå‡è®¾ä»»åŠ¡å¤„ç†è¿‡ç¨‹è¾ƒé•¿ï¼ŒåŠ¨æ€ spawn å¼€é”€å¯ä»¥å¿½ç•¥ã€‚
/// - ä¸å†å­˜åœ¨ä¸­å¿ƒè°ƒåº¦å™¨ï¼Œæ‰€æœ‰ä¼˜å…ˆçº§ç”±å…¶è‡ªèº«ä»»åŠ¡â€œè‡ªæ²»æ¶ˆè´¹â€ã€‚
/// - ç©ºé—²æ—¶ä¸ä¼šæœ‰å¿™ç­‰å¾…ï¼ŒèŠ‚çœ CPU èµ„æºã€‚
///
#[derive(Debug, Clone)]
pub(crate) struct Dispatcher {
    pub(crate) external_tx: TaskSender,
    // task_queues: PriorityTaskQueue,
    // semaphore: Arc<Semaphore>,
}

impl Dispatcher {
    pub fn new(running_tasks: RunningTasks) -> Self {
        let (external_tx, external_rx) = tokio::sync::mpsc::unbounded_channel();

        Self::start_internal_task(external_rx, running_tasks, Arc::new(Semaphore::new(50)));
        tracing::info!("Dispatcher å¯åŠ¨å®Œæˆï¼Œå¼€å§‹ç›‘å¬å¤–éƒ¨ä»»åŠ¡è¾“å…¥...");
        Self {
            external_tx, // task_queues: Arc::new(tokio::sync::Mutex::new(BTreeMap::new())),
                         // semaphore: Arc::new(Semaphore::new(50)), // æœ€å¤§å¹¶å‘æ•°å¯è°ƒæ•´
        }
    }

    /// å¯åŠ¨å†…éƒ¨å¼‚æ­¥è°ƒåº¦å™¨ï¼š
    ///
    /// - åŠ¨æ€æ¥æ”¶å¤–éƒ¨ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    /// - è‹¥è¯¥ä¼˜å…ˆçº§æœªæ³¨å†Œæ¶ˆè´¹é€šé“ï¼Œåˆ™è‡ªåŠ¨åˆ›å»ºé€šé“ + å¯åŠ¨ Tokio task å¤„ç†å™¨
    /// - æ¯ä¸ªä¼˜å…ˆçº§é€šé“ç‹¬ç«‹æ¶ˆè´¹ä»»åŠ¡ï¼Œé¿å…å…¨å±€é”æˆ–æŠ¢å èµ„æº
    fn start_internal_task(
        mut external_rx: tokio::sync::mpsc::UnboundedReceiver<(Priority, Vec<TaskQueueEntity>)>,
        running_tasks: RunningTasks,
        semaphore: Arc<Semaphore>,
    ) {
        tokio::spawn(async move {
            let mut priority_senders: HashMap<Priority, mpsc::UnboundedSender<TaskQueueEntity>> =
                HashMap::new();
            let category_limit = TASK_CATEGORY_LIMIT
                .iter()
                .cloned()
                .collect::<HashMap<_, _>>();

            while let Some((priority, tasks)) = external_rx.recv().await {
                tracing::info!("æ”¶åˆ° {} ä¸ªä»»åŠ¡ï¼Œä¼˜å…ˆçº§ = {}", tasks.len(), priority,);
                let sender = priority_senders.entry(priority).or_insert_with(|| {
                    tracing::info!("åˆ›å»ºæ–°çš„ä¼˜å…ˆçº§ {} é€šé“å¹¶å¯åŠ¨ä»»åŠ¡æ¶ˆè´¹å™¨", priority);
                    Self::create_priority_channel_task(
                        priority,
                        running_tasks.clone(),
                        semaphore.clone(),
                        category_limit.clone(),
                    )
                });

                for task in tasks {
                    let _ = sender.send(task);
                }
            }
            tracing::warn!("Dispatcher çš„ external_rx å…³é—­ï¼Œä»»åŠ¡ç›‘å¬ç»“æŸ");
        });
    }

    /// ä¸ºæŸä¸ªä¼˜å…ˆçº§åŠ¨æ€åˆ›å»ºé€šé“åŠç»‘å®šå¼‚æ­¥æ¶ˆè´¹ä»»åŠ¡
    ///
    /// è¿”å›è¯¥ä¼˜å…ˆçº§çš„ `UnboundedSender<TaskQueueEntity>`ï¼Œç”¨äºåç»­æŠ•é€’ä»»åŠ¡

    fn create_priority_channel_task(
        priority: u8,
        running_tasks: RunningTasks,
        semaphore: Arc<Semaphore>,
        category_limit: HashMap<TaskType, usize>,
    ) -> mpsc::UnboundedSender<TaskQueueEntity> {
        let (tx, mut rx) = mpsc::unbounded_channel::<TaskQueueEntity>();
        // let tx_c = tx.clone(); // ä¸éœ€è¦é‡æ’ä½†ä¿ç•™ clone ç”¨äºå…¶ä»–æƒ…å†µ
        tokio::spawn(async move {
            let category_counter = Arc::new(Mutex::new(HashMap::<TaskType, usize>::new()));

            while let Some(task_entity) = rx.recv().await {
                let category_counter = category_counter.clone();
                let running_tasks = running_tasks.clone();
                let semaphore = semaphore.clone();
                let category_limit = category_limit.clone();
                tokio::spawn(async move {
                    Self::handle_task_entity(
                        priority,
                        task_entity,
                        category_counter,
                        &category_limit,
                        running_tasks,
                        semaphore,
                    )
                    .await;
                });
            }
            tracing::warn!("ä¼˜å…ˆçº§é€šé“æ¶ˆè´¹è€…é€€å‡ºï¼Œè¯¥é€šé“å·²å…³é—­");
        });
        tx
    }

    /// æ‰§è¡Œä»»åŠ¡å¤„ç†é€»è¾‘ï¼ŒåŒ…å«ï¼š
    /// - ä»»åŠ¡ç±»å‹é™é€Ÿ
    /// - å¹¶å‘æ§åˆ¶ï¼ˆSemaphoreï¼‰
    /// - å»é‡ï¼ˆRunningTasksï¼‰
    /// - ä»»åŠ¡è°ƒåº¦ï¼ˆspawnï¼‰
    async fn handle_task_entity(
        priority: u8,
        task_entity: TaskQueueEntity,
        category_counter: Arc<Mutex<HashMap<TaskType, usize>>>,
        category_limit: &HashMap<TaskType, usize>,
        running_tasks: RunningTasks,
        semaphore: Arc<Semaphore>,
    ) {
        let task_id = &task_entity.id;

        let task: Task = match (&task_entity).try_into() {
            Ok(t) => t,
            Err(_) => {
                tracing::warn!("ä»»åŠ¡è§£æå¤±è´¥ï¼Œè·³è¿‡ï¼šid = {:?}", task_id);
                return;
            } // è½¬æ¢å¤±è´¥ç›´æ¥è·³è¿‡
        };

        // === é™é€Ÿé€»è¾‘ ===
        let category = task.get_type();

        // let limiter = get_rate_limiter(&category);

        // limiter.until_ready().await;

        let limit = *category_limit.get(&category).unwrap_or(&1);

        // === ç­‰å¾…ç±»å‹é™é€Ÿçª—å£ ===
        loop {
            let mut counter = category_counter.lock().await;
            let count = counter.entry(category.clone()).or_insert(0);
            if *count < limit {
                *count += 1;
                tracing::info!(
                    "ä»»åŠ¡ç±»å‹ {:?} ä¼˜å…ˆçº§ {} æœªè¾¾åˆ°é™é€Ÿä¸Šé™ ({}/{}), å¾…æ‰§è¡Œï¼š{}",
                    category,
                    priority,
                    *count,
                    limit,
                    task_id
                );
                break;
            } else {
                tracing::info!(
                    "ä»»åŠ¡ç±»å‹ {:?} ä¼˜å…ˆçº§ {} è¾¾åˆ°é™é€Ÿä¸Šé™ ({}/{}), ç­‰å¾…ä¸­ï¼š{}",
                    category,
                    priority,
                    *count,
                    limit,
                    task_id
                );
            }
            drop(counter); // é‡Šæ”¾é”ï¼Œé¿å…æ­»é”
            tokio::time::sleep(tokio::time::Duration::from_millis(200)).await;
        }

        // === å»é‡é€»è¾‘ + å¹¶å‘æ§åˆ¶ ===
        let task_id = task_entity.id.clone();
        if running_tasks.insert(task_id.clone()) {
            tracing::info!(
                "å‡†å¤‡æ‰§è¡Œä»»åŠ¡ {}ï¼Œç±»å‹ = {:?}ï¼Œä¼˜å…ˆçº§ = {}, å½“å‰å¹¶å‘ = {}",
                task_id,
                category,
                priority,
                running_tasks.len()
            );

            // å¦‚æœæˆåŠŸæ’å…¥ï¼Œè¯´æ˜ä¹‹å‰æ²¡æœ‰è¯¥ä»»åŠ¡ï¼Œå¼€å§‹å¤„ç†
            let permit = semaphore.acquire_owned().await.unwrap();
            let running_tasks_inner = running_tasks.clone();
            let category_counter = category_counter.clone();

            tokio::spawn(async move {
                tracing::info!("å¼€å§‹æ‰§è¡Œä»»åŠ¡ {}", task_id);
                TaskManager::process_single_task(task_entity, running_tasks_inner).await;
                let mut counter = category_counter.lock().await;
                if let Some(count) = counter.get_mut(&category) {
                    *count = count.saturating_sub(1);
                    tracing::info!(?category, current = *count, "ä»»åŠ¡è®¡æ•° -1");
                }
                drop(permit); // é‡Šæ”¾ä¿¡å·é‡
                tracing::info!("ä»»åŠ¡ {} æ‰§è¡Œå®Œæˆ", task_id);
            });

            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
        } else {
            tracing::info!("ä»»åŠ¡ {} å·²åœ¨è¿è¡Œä¸­ï¼Œè·³è¿‡é‡å¤æ‰§è¡Œ", task_id);
        }
    }
}

// /// ä»»åŠ¡è°ƒåº¦å™¨ `task_dispatcher`
// ///
// /// è¯¥è°ƒåº¦å™¨è®¾è®¡ç”¨äºå¤šä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—çš„å¼‚æ­¥è°ƒåº¦ä¸æ‰§è¡Œï¼Œ
// /// ç»“åˆäº†æ— ç•Œé˜Ÿåˆ—ç”¨äºæ¥æ”¶ä»»åŠ¡å’Œæœ‰é™é˜Ÿåˆ—æ§åˆ¶å¹¶å‘ï¼Œ
// /// åŒæ—¶å®ç°ä¼˜å…ˆçº§å…¬å¹³è½®è¯¢æœºåˆ¶ï¼Œé˜²æ­¢é«˜ä¼˜å…ˆçº§ä»»åŠ¡é¥¿æ­»ä½ä¼˜å…ˆçº§ä»»åŠ¡ã€‚
// ///
// /// ## ç»“æ„ä¸æµç¨‹
// ///
// /// ```text
// ///  ä¸Šå±‚æ¨¡å— / å¤–éƒ¨è°ƒç”¨
// ///            â”‚
// ///            â–¼
// ///  UnboundedSender<(priority, Vec<Task>)>  (æ— ç•Œé€šé“)
// ///            â”‚
// ///   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
// ///   â”‚ ä»»åŠ¡æ¥æ”¶å¤„ç†ä»»åŠ¡            â”‚
// ///   â”‚ (å°†ä»»åŠ¡æŒ‰ä¼˜å…ˆçº§æ”¾å…¥å†…éƒ¨é˜Ÿåˆ—)  â”‚
// ///   â–¼                      internal priority queues (BTreeMap<Priority, VecDeque<Task>>)
// ///                          (ç”¨ Mutex ä¿æŠ¤)
// ///            â”‚
// ///  è°ƒåº¦å™¨è½®è¯¢ä»»åŠ¡é˜Ÿåˆ—ï¼Œ
// ///  æŒ‰ä¼˜å…ˆçº§å…¬å¹³è½®è¯¢æ–¹å¼ä»æ¯ä¸ªé˜Ÿåˆ—å–æœ‰é™ä»»åŠ¡ï¼ˆæœ€å¤§ N ä¸ªï¼‰
// ///            â”‚
// ///  æœ‰ç•Œä¿¡å·é‡(Semaphore)é™åˆ¶æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
// ///            â”‚
// ///  tokio::spawn å¯åŠ¨ä»»åŠ¡å¼‚æ­¥æ‰§è¡Œï¼Œ
// ///  ä»»åŠ¡æ‰§è¡Œç»“æŸåé‡Šæ”¾ä¿¡å·é‡è®¸å¯
// /// ```
// ///
// /// ## ä¸»è¦ç»„ä»¶
// ///
// /// - `external_tx`ï¼š
// ///   å¤–éƒ¨ä»»åŠ¡å‘é€é€šé“ï¼ˆæ— ç•Œï¼‰ï¼Œå‘é€ `(ä¼˜å…ˆçº§, Vec<Task>)`ï¼Œä¿è¯å¤–éƒ¨è°ƒç”¨ä¸é˜»å¡ã€‚
// ///
// /// - `task_queues`ï¼š
// ///   å†…éƒ¨ä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—ï¼Œ
// ///   ä½¿ç”¨ `BTreeMap<u8, VecDeque<TaskQueueEntity>>` ä»¥ä¼˜å…ˆçº§æ’åºï¼Œ
// ///   é€šè¿‡å¼‚æ­¥ Mutex ä¿æŠ¤å¹¶å‘å®‰å…¨ã€‚
// ///
// /// - `semaphore`ï¼š
// ///   é™åˆ¶æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°ï¼ˆä¾‹å¦‚ 50ï¼‰ï¼Œé˜²æ­¢è¿‡è½½ã€‚
// ///
// /// - ä»»åŠ¡æ¥æ”¶ä»»åŠ¡ï¼ˆä»»åŠ¡æ¥æ”¶å¾ªç¯ï¼‰ï¼š
// ///   æŒç»­ç›‘å¬ `external_rx`ï¼Œ
// ///   å°†å¤–éƒ¨ä¼ æ¥çš„ä»»åŠ¡æŒ‰ä¼˜å…ˆçº§åˆ†ç±»æ”¾å…¥å¯¹åº”é˜Ÿåˆ—ã€‚
// ///
// /// - è°ƒåº¦å™¨ä¸»å¾ªç¯ï¼š
// ///   è½®è¯¢æ‰€æœ‰ä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œ
// ///   æ¯ä¸ªé˜Ÿåˆ—æœ€å¤šå– `MAX_TASKS_PER_ROUND` ä»»åŠ¡ï¼Œ
// ///   èšåˆåä¾æ¬¡å¯åŠ¨å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œï¼Œ
// ///   å¯åŠ¨å‰é€šè¿‡ `running_tasks` é›†åˆé¿å…é‡å¤è¿è¡Œç›¸åŒä»»åŠ¡ã€‚
// ///
// /// - å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œï¼š
// ///   é€šè¿‡ `TaskManager::process_single_task` å¤„ç†å•ä¸ªä»»åŠ¡ï¼Œ
// ///   å¹¶ç¡®ä¿æ‰§è¡Œå®Œæˆåé‡Šæ”¾ä¿¡å·é‡è®¸å¯ï¼Œ
// ///   æ§åˆ¶å¹¶å‘æ•°ï¼Œä¿æŒç³»ç»Ÿç¨³å®šã€‚
// ///
// ///
// /// ## å…¬å¹³è°ƒåº¦è¯´æ˜
// ///
// /// è°ƒåº¦å™¨æ¯è½®ä»æ‰€æœ‰ä¼˜å…ˆçº§é˜Ÿåˆ—è½®æµå–ä»»åŠ¡ï¼Œ
// /// é¿å…é«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¸€ç›´å ç”¨èµ„æºå¯¼è‡´ä½ä¼˜å…ˆçº§ä»»åŠ¡é¥¥é¥¿ï¼Œ
// /// ä¿è¯å„ä¼˜å…ˆçº§ä»»åŠ¡å‡èƒ½å¾—åˆ°åˆç†æ‰§è¡Œæœºä¼šã€‚
// ///
// /// ## æ€§èƒ½ä¼˜åŒ–
// ///
// /// - ç©ºè½¬æ—¶å»¶æ—¶ 200ms é¿å…å¿™ç­‰å¾…ã€‚
// /// - æ¯å¯åŠ¨ä¸€ä¸ªä»»åŠ¡åå»¶æ—¶ 100msï¼Œ
// ///   é˜²æ­¢ç¬æ—¶è¿‡å¤šå¹¶å‘å¯åŠ¨å¯¼è‡´èµ„æºå†²å‡»ã€‚
// ///
// pub(super) fn task_dispatcher(
//     &self,
//     running_tasks: RunningTasks,
// ) -> tokio::sync::mpsc::UnboundedSender<(u8, Vec<TaskQueueEntity>)> {
//     // å¤–éƒ¨æ¥å£æŒ‰ (priority, Vec<Task>) å‘é€
//     let (external_tx, mut external_rx) =
//         tokio::sync::mpsc::unbounded_channel::<(u8, Vec<TaskQueueEntity>)>();

//     // æ¯ä¸ªä¼˜å…ˆçº§çš„ä»»åŠ¡é˜Ÿåˆ—ï¼ˆu8 ä¼˜å…ˆçº§ â†’ VecDequeï¼‰
//     let task_queues = Arc::clone(&self.task_queues);

//     // æ”¶é›†ä»»åŠ¡ï¼šä¸æ–­å°†æ¥æ”¶åˆ°çš„ä»»åŠ¡å¡«å…¥å¯¹åº”ä¼˜å…ˆçº§é˜Ÿåˆ—
//     tokio::spawn(async move {
//         while let Some((priority, task_list)) = external_rx.recv().await {
//             let mut queues = task_queues.lock().await;
//             let queue = queues.entry(priority).or_default();
//             for task in task_list {
//                 queue.push_back(task);
//             }
//         }
//     });

//     // ä¸»è°ƒåº¦å™¨ï¼Œè½®è¯¢å„ä¸ªä¼˜å…ˆçº§é˜Ÿåˆ—è¿›è¡Œå…¬å¹³åˆ†å‘
//     let task_queues = Arc::clone(&self.task_queues);
//     let semaphore = Arc::clone(&self.semaphore);

//     tokio::spawn(async move {
//         let category_limit: HashMap<TaskType, usize> =
//             TASK_CATEGORY_LIMIT.iter().cloned().collect();

//         loop {
//             let mut round: Vec<TaskQueueEntity> = vec![];
//             let mut category_counter: HashMap<TaskType, usize> = HashMap::new();
//             {
//                 let mut queues = task_queues.lock().await;
//                 for (_priority, queue) in queues.iter_mut() {
//                     let mut i = 0;
//                     while i < queue.len() {
//                         if let Some(task) = queue.get(i) {
//                             let task: Task = task.try_into().unwrap();
//                             let category = task.get_type();
//                             let limit = *category_limit.get(&category).unwrap_or(&1);
//                             let count = category_counter.entry(category).or_insert(0);

//                             if *count < limit {
//                                 let task = queue.remove(i).unwrap();
//                                 round.push(task);
//                                 *count += 1;
//                             } else {
//                                 i += 1;
//                             }
//                         } else {
//                             break;
//                         }
//                     }
//                 }
//             }

//             // ç©ºè½¬æ—¶é€‚å½“ sleepï¼Œé¿å… busy loop
//             if round.is_empty() {
//                 tokio::time::sleep(tokio::time::Duration::from_millis(200)).await;
//                 continue;
//             }

//             // å®é™…æ‰§è¡Œä»»åŠ¡
//             for task in round {
//                 let task_id = task.id.clone();
//                 if running_tasks.insert(task_id.clone()) {
//                     let semaphore = Arc::clone(&semaphore);
//                     let running_tasks = Arc::clone(&running_tasks);

//                     let permit = semaphore.acquire_owned().await.unwrap();
//                     tokio::spawn(async move {
//                         TaskManager::process_single_task(task, running_tasks).await;
//                         drop(permit);
//                     });

//                     // å¯é€‰å°å»¶è¿Ÿé¿å…ç¬æ—¶å¹¶å‘å†²å‡»
//                     tokio::time::sleep(tokio::time::Duration::from_millis(100)).await;
//                 }
//             }
//         }
//     });
//     external_tx
// }
